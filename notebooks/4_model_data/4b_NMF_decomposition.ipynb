{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e08248b-8eeb-43a4-83b7-c04cf05b6e24",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad89bca-7c8f-497a-8cad-9915e7326f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base imports\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Compute imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from scipy import spatial as sp\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.cluster import hierarchy as hc\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "# Plotting imports\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly import express as px\n",
    "\n",
    "# ML import\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c069123-5f8b-46e0-a411-d604eb3e3faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genes = pd.read_pickle('../../data/processed/cd-hit-results/sim80/Ebacter_strain_by_gene.pickle.gz')\n",
    "df_genes.fillna(0, inplace=True)\n",
    "df_genes = df_genes.sparse.to_dense().astype('int8')\n",
    "\n",
    "df_genes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dff0261-cea6-47a6-9886-55bc6c974a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import full metadata\n",
    "metadata = pd.read_csv('../../data/metadata/mash_scrubbed_species_metadata.csv', index_col=0, dtype='object')\n",
    "\n",
    "# Filter metadata for Complete sequences only\n",
    "metadata_complete = metadata[metadata.genome_status == 'Complete'] # filter for only Complete sequences\n",
    "\n",
    "# Filter P matrix for Complete sequences only\n",
    "df_genes_complete = df_genes[metadata_complete.genome_id]\n",
    "inCompleteseqs = df_genes_complete.sum(axis=1) > 0 # filter for genes found in complete sequences\n",
    "df_genes_complete = df_genes_complete[inCompleteseqs]\n",
    "\n",
    "df_genes_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a25d9-3ce2-437c-b3a2-62b73a20e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select genomes have too many plasmids\n",
    "bad_genomes = metadata.loc[(metadata.plasmids.apply(float) > 20)]\n",
    "metadata = metadata.drop(bad_genomes.index)\n",
    "df_genes = df_genes.drop(bad_genomes.genome_id, axis=1)\n",
    "df_genes = df_genes[df_genes.sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff802930-7522-4891-aec3-d5180da7ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sparse representations of the P matrix\n",
    "df_genes_complete_sparse = df_genes_complete.astype(pd.SparseDtype(\"int8\", 0))\n",
    "\n",
    "coo_genes = df_genes_complete_sparse.sparse.to_coo()\n",
    "csr_genes = csr_matrix(coo_genes)\n",
    "csr_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4425ecc3-0ffd-41a3-b353-ba3fe0c16167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse P matrix into a frequency matrix\n",
    "df_genes_freq = pd.DataFrame(index=df_genes_complete_sparse.index, data=csr_genes.sum(axis=1), columns=['freq'])\n",
    "df_genes_freq = df_genes_freq.freq\n",
    "df_genes_freq.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474ac371-d780-4e39-b37c-ad186349a943",
   "metadata": {},
   "source": [
    "## Full accessory genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724331c9-bc41-461f-910a-01ca7c2743f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import (full) accessory genome\n",
    "df_acc_complete = pd.read_pickle('../../data/processed/CAR_genomes/df_acc_complete.pickle')\n",
    "df_acc_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba3301-8b5e-4178-84b2-b9d61d662872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cutoff frequency between accessory & rare genomes\n",
    "acc_min_freq = 100 * df_acc_complete.sum(axis=1).min() / df_genes_complete.shape[1]\n",
    "acc_min_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b8971c-2773-46c0-bf4d-3aa9098f815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cutoff frequency between accessory & core genomes\n",
    "acc_max_freq = 100 * df_acc_complete.sum(axis=1).max() / df_genes_complete.shape[1]\n",
    "acc_max_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e62551f-3cb9-436a-b28d-b82b0b1a716b",
   "metadata": {},
   "source": [
    "## Reduced accessory genome (min to 75%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe13ec0-090f-4933-9d5f-ca5a9ff57740",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## NOTE FROM JOSH: is this reducing the min to 75% or the max to 75%??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133afff2-213b-4350-9fb5-4f04d42b9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond1 = df_genes_freq >= acc_min_freq\n",
    "cond2 = df_genes_freq <= df_acc_complete.shape[1] * 0.75\n",
    "\n",
    "df_acc_75 = df_genes_complete.loc[df_genes_freq[cond1 & cond2].sort_values().index]\n",
    "df_acc_75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c18b7d-b4e5-45b9-9ef2-8a23d6709aa4",
   "metadata": {},
   "source": [
    "## Infrequent accessory genome (min to 50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95dba54-064b-4cc4-885e-de3080440476",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond1 = df_genes_freq >= acc_min_freq\n",
    "cond2 = df_genes_freq <= df_acc_complete.shape[1] * 0.5\n",
    "\n",
    "df_acc_50 = df_genes_complete.loc[df_genes_freq[cond1 & cond2].sort_values().index]\n",
    "df_acc_50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a29de-a279-4f7f-bb46-81fdb70ccb8f",
   "metadata": {},
   "source": [
    "## Sparse accessory genome (min to 25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3572bef6-b3c6-4c01-9e41-5595d683382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond1 = df_genes_freq >= acc_min_freq\n",
    "cond2 = df_genes_freq <= df_acc_complete.shape[1] * 0.25\n",
    "\n",
    "df_acc_25 = df_genes_complete.loc[df_genes_freq[cond1 & cond2].sort_values().index]\n",
    "df_acc_25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e1b212-8e89-4b97-9f82-e2b134fa9dd6",
   "metadata": {},
   "source": [
    "# NMF decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a58cd2-a2e7-46d2-88b0-cdf538083eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANK = 19# Enter your rank here (from Mash clustering, notebook 2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbc55f9-fa87-4e4e-b553-b370bf45722d",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e663ce-0825-4907-ba84-7b7c062f8919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util functions for consensus clustering (from Nimfa)\n",
    "from operator import mul, eq, ne, add, ge, le, itemgetter\n",
    "from operator import truediv as div\n",
    "\n",
    "def argmax(X, axis=None):\n",
    "    idxX = np.asmatrix(X).argmax(axis)\n",
    "    if axis is None:\n",
    "        eX = X[idxX // X.shape[1], idxX % X.shape[1]]\n",
    "    elif axis == 0:\n",
    "        eX = [X[idxX[0, idx], col]\n",
    "              for idx, col in zip(range(X.shape[1]), range(X.shape[1]))]\n",
    "    else:\n",
    "        eX = [X[row, idxX[idx, 0]]\n",
    "              for row, idx in zip(range(X.shape[0]), range(X.shape[0]))]\n",
    "    return eX, idxX\n",
    "\n",
    "\n",
    "def repmat(X, m, n):\n",
    "    return np.tile(np.asmatrix(X), (m, n))\n",
    "\n",
    "\n",
    "def elop(X, Y, op):\n",
    "    try:\n",
    "        zp1 = op(1, 0)\n",
    "        zp2 = op(0, 0)\n",
    "        zp = zp1 != 0 or zp2 != 0\n",
    "    except:\n",
    "        zp = 0\n",
    "    \n",
    "    try:\n",
    "        X[X == 0] = np.finfo(X.dtype).eps\n",
    "        Y[Y == 0] = np.finfo(Y.dtype).eps\n",
    "    except ValueError:\n",
    "        return op(np.mat(X), np.mat(Y))\n",
    "    \n",
    "    return op(np.mat(X), np.mat(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82855cd4-6aa8-49fc-a741-1f0928275eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectivity(X, H):\n",
    "    \"\"\"\n",
    "    Compute the connectivity matrix for the samples based on their mixture coefficients. \n",
    "    \n",
    "    The connectivity matrix C is a symmetric matrix which shows the shared membership of the samples: entry C_ij is 1 iff sample i and \n",
    "    sample j belong to the same cluster, 0 otherwise. Sample assignment is determined by its largest expression value. \n",
    "    \n",
    "    Return connectivity matrix.\n",
    "    \n",
    "    :param idx: Used in the multiple NMF model. In factorizations following\n",
    "        standard NMF model or nonsmooth NMF model ``idx`` is always None.\n",
    "    :type idx: None or `str` with values 'coef' or 'coef1' (`int` value of 0 or 1, respectively) \n",
    "    \"\"\"\n",
    "    _, idx = argmax(H, axis=0)\n",
    "    mat1 = repmat(idx, X.shape[1], 1)\n",
    "    mat2 = repmat(idx.T, 1, X.shape[1])\n",
    "    conn = elop(mat1, mat2, eq)\n",
    "    \n",
    "    return np.mat(conn, dtype='d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05edc0d-686d-4dec-8fce-5ec14d287022",
   "metadata": {},
   "source": [
    "## Consensus model 1: Full accessory genome\n",
    "\n",
    "__Main model we will be working with__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe338f9c-44c8-478e-8fa3-35dd5548801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input matrix\n",
    "X = df_acc_complete\n",
    "\n",
    "# Rank (determined by Mash)\n",
    "rank = RANK\n",
    "\n",
    "# Initialize DataFrame of error metrics (as list of dicts)\n",
    "nmf_errors = []\n",
    "\n",
    "# Initialize dict of low-dim representations (phylons)\n",
    "W_dict = {}\n",
    "\n",
    "# Initialize dict of corresponding affinities\n",
    "H_dict = {}\n",
    "\n",
    "# Perform NMF 50 times\n",
    "for i in trange(3):\n",
    "    # Initialize NMF object\n",
    "    model = NMF(\n",
    "        n_components=rank,\n",
    "        init='nndsvd',\n",
    "        max_iter=5_000,\n",
    "        random_state=i\n",
    "    )\n",
    "    \n",
    "    # Fit and transform the model\n",
    "    W = model.fit_transform(X)\n",
    "    H = model.components_\n",
    "\n",
    "    # Typecast as DataFrames\n",
    "    init_names = [f'phylon{i}' for i in range(rank)]\n",
    "    W = pd.DataFrame(W, index=X.index, columns=init_names)\n",
    "    H = pd.DataFrame(H, index=init_names, columns=X.columns)\n",
    "\n",
    "    # Save matrices to respective dicts\n",
    "    W_dict[i] = W\n",
    "    H_dict[i] = H\n",
    "    \n",
    "    # Reconstruct matrix\n",
    "    X_reconstructed = np.dot(W, H)\n",
    "    X_diff = X - X_reconstructed\n",
    "    \n",
    "    # Calculate errors\n",
    "    ssr = np.sum(X_diff**2, axis=0).sum(axis=0)\n",
    "    frobenius = np.linalg.norm(X_diff, 'fro')\n",
    "    \n",
    "    mae = median_absolute_error(X, X_reconstructed)\n",
    "    rmse = np.sqrt(mean_squared_error(X, X_reconstructed))\n",
    "    \n",
    "    # Save errors to DataFrame (as list of dicts)\n",
    "    error = {}\n",
    "    error['Run'] = i+1\n",
    "    error['SSR'] = ssr\n",
    "    error['Frobenius'] = frobenius\n",
    "    error['MAE'] = mae\n",
    "    error['RMSE'] = rmse\n",
    "    \n",
    "    nmf_errors.append(error)\n",
    "\n",
    "# Typecast to DataFrame\n",
    "df_nmf_errors = pd.DataFrame(nmf_errors).set_index('Run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db3be6-b8d0-4d91-a7e8-282a91c8072d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the new dictionary\n",
    "conn_dict = {}\n",
    "\n",
    "# Loop over each matrix in the H_dict dictionary\n",
    "for key, H in H_dict.items():\n",
    "    conn_dict[key] = connectivity(X.values, H.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9117ca1-df14-455a-b72f-17dccb45a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consensus matrix for these runs (H matrix, default)\n",
    "consensus_matrix = np.zeros(shape=conn_dict[0].shape)\n",
    "\n",
    "for key, conn_matrix in conn_dict.items():\n",
    "    consensus_matrix += conn_matrix\n",
    "\n",
    "consensus_matrix /= len(conn_dict)\n",
    "\n",
    "df_consensus_matrix = pd.DataFrame(consensus_matrix, index=X.columns, columns=X.columns)\n",
    "df_consensus_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6ee595-a5cc-41d1-8740-36eb8d54f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to get different number of clusters\n",
    "\n",
    "# Minimum acceptable value for robust clusters = 50%\n",
    "thresh = 0.5\n",
    "\n",
    "# change this to get a different linkage (by method)\n",
    "df_consensus_dist = 1 - df_consensus_matrix\n",
    "link = hc.linkage(scipy.spatial.distance.squareform(df_consensus_dist), method='ward')\n",
    "\n",
    "# retrieve clusters using fcluster\n",
    "dist = scipy.spatial.distance.squareform(df_consensus_dist)\n",
    "\n",
    "consensus_clst = pd.DataFrame(index=X.columns)\n",
    "consensus_clst['cluster'] = hc.fcluster(link, thresh * dist.max(), 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8772ca-284d-47dc-b3c5-eb528295400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bar plot showing sizes of each consensus strain cluster (at thresh = 0.5)\n",
    "# sns.barplot(\n",
    "#     x=consensus_clst.cluster.value_counts().sort_index().index,\n",
    "#     y=consensus_clst.cluster.value_counts().sort_index().values\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6056a66f-13f7-42f1-bd85-9a47faf129c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot showing sizes of each consensus strain cluster (at thresh = 0.5)\n",
    "px.bar(\n",
    "    x=consensus_clst.cluster.value_counts().sort_index().index,\n",
    "    y=consensus_clst.cluster.value_counts().sort_index().values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d24e6f7-5480-4de2-b32b-7a4c862cc05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color each NMF cluster (default matplotlib colors)\n",
    "\n",
    "#cm = matplotlib.colormaps.get_cmap('tab20')\n",
    "cmb = matplotlib.colormaps.get_cmap('tab20b')\n",
    "cmc = matplotlib.colormaps.get_cmap('tab20c')\n",
    "cm_colors = cmb.colors + cmc.colors\n",
    "\n",
    "consensus_clr = dict(zip(sorted(consensus_clst.cluster.unique()), cm_colors))\n",
    "consensus_clst['color'] = consensus_clst.cluster.map(consensus_clr)\n",
    "\n",
    "print('Number of colors: ', len(consensus_clr))\n",
    "print('Number of clusters', len(consensus_clst.cluster.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40169824-22cf-43a3-9201-22725c02d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 9\n",
    "\n",
    "#legend_TN = [patches.Patch(color=c, label=l) for l,c in mash_color_dict_31.items()] # Mash cluster for legend\n",
    "\n",
    "sns.set(rc={'figure.facecolor':'white'})\n",
    "g = sns.clustermap(\n",
    "    df_consensus_matrix,\n",
    "    figsize=(size,size),\n",
    "    row_linkage=link,\n",
    "    #row_colors=phylogroup_clst.color, # Phylogroup colors on left\n",
    "    col_linkage=link,\n",
    "    #col_colors=clst.color, # Mash cluster on top\n",
    "    yticklabels=False,\n",
    "    xticklabels=False,\n",
    "    cmap='hot_r'\n",
    ")\n",
    "\n",
    "#l2=g.ax_heatmap.legend(loc='upper left', bbox_to_anchor=(1.01,0.75), handles=legend_TN, frameon=True)\n",
    "#l2.set_title(title='Mash cluster',prop={'size':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bea4c6-fe39-43a0-9057-04788377bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper diagonal elements of consensus\n",
    "avec = np.array([consensus_matrix[i, j] for i in range(consensus_matrix.shape[0] - 1)\n",
    "                 for j in range(i + 1, consensus_matrix.shape[1])])\n",
    "\n",
    "# consensus entries are similarities, conversion to distances\n",
    "Y = 1 - avec\n",
    "Z = hc.linkage(Y, method='ward')\n",
    "\n",
    "# cophenetic correlation coefficient of a hierarchical clustering\n",
    "# defined by the linkage matrix Z and matrix Y from which Z was\n",
    "# generated\n",
    "coph_cor, _ = cophenet(Z, Y)\n",
    "\n",
    "coph_cor # Cophenetic correlation of consensus matrix (ideally 0.7 or higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee05c3f-af69-43e4-a736-deaad2e4b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion = np.sum(4 * np.multiply(consensus_matrix - 0.5, consensus_matrix - 0.5)) / consensus_matrix.size\n",
    "\n",
    "dispersion # Dispersion coefficient of consensus matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91a1d4e-2742-47d3-bb2c-92f43a5d321d",
   "metadata": {},
   "source": [
    "## Consensus model 2: Reduced accessory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a99c82-5c76-4c39-adcb-a3789b5514b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input matrix\n",
    "X = df_acc_75.copy()\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c8e78-48a6-4c73-9ad4-4a6b60f687e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of NMF runs (~3 min for 50 runs)\n",
    "n_runs = 3\n",
    "\n",
    "# Rank of NMF (Mash rank for complete strains)\n",
    "rank = RANK\n",
    "\n",
    "# Max iterations per run\n",
    "max_iter = 5_000\n",
    "\n",
    "# Initialize dictionaries to store W and H matrices\n",
    "W_dict_red = {}\n",
    "H_dict_red = {}\n",
    "\n",
    "# Initialize dictionary to store NMF model\n",
    "nmf_red_dict = {}\n",
    "\n",
    "# Store model errors (becomes pandas DataFrame)\n",
    "nmf_red_errors = []\n",
    "\n",
    "# Run NMF num_runs times and store W and H matrices in dictionaries\n",
    "for i in trange(n_runs):\n",
    "    nmf_red = NMF(\n",
    "        n_components=rank,\n",
    "        init='nndsvd', # gives sparser basis matrix\n",
    "        max_iter=max_iter,\n",
    "        random_state=i+731\n",
    "    )\n",
    "    W = nmf_red.fit_transform(X) # basis matrix (gene groupings)\n",
    "    H = nmf_red.components_ # coefficients matrix (strain groupings)\n",
    "    W_dict_red[i] = W\n",
    "    H_dict_red[i] = H\n",
    "    \n",
    "    X_approx = pd.DataFrame(\n",
    "        np.dot(W, H),\n",
    "        index=X.index,\n",
    "        columns=X.columns\n",
    "    )\n",
    "    \n",
    "    nmf_red_dict[i] = nmf_red    \n",
    "    \n",
    "    # Store error metrics\n",
    "    entry = {}\n",
    "    entry['run'] = i\n",
    "    entry['rmse']  = np.sqrt(mean_squared_error(X, X_approx))\n",
    "    entry['mae']  = median_absolute_error(X, X_approx)\n",
    "    entry['fro'] = np.linalg.norm(X - X_approx)\n",
    "    entry['ssr'] = np.square(X - X_approx).values.flatten().sum()\n",
    "    \n",
    "    nmf_red_errors.append(entry)\n",
    "\n",
    "nmf_red_errors = pd.DataFrame(nmf_red_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e924d-5378-46c6-933b-c0ad52eae5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the new dictionary\n",
    "conn_dict_red = {}\n",
    "\n",
    "# Loop over each matrix in the H_dict dictionary\n",
    "for key, H in H_dict_red.items():\n",
    "    conn_dict_red[key] = connectivity(X, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74732ffc-b511-43e5-9e83-0069fd2a0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consensus matrix for these runs (H matrix, default)\n",
    "consensus_matrix_red = np.zeros(shape=conn_dict_red[0].shape)\n",
    "\n",
    "for key, conn_matrix in conn_dict_red.items():\n",
    "    consensus_matrix_red += conn_matrix\n",
    "\n",
    "consensus_matrix_red /= len(conn_dict_red)\n",
    "\n",
    "df_consensus_matrix_red = pd.DataFrame(consensus_matrix_red, index=X.columns, columns=X.columns)\n",
    "df_consensus_matrix_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26969f4-f447-41bb-9f00-7218821b0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to get different number of clusters\n",
    "\n",
    "# Minimum acceptable value for robust clusters = 50%\n",
    "thresh = 0.5\n",
    "\n",
    "# change this to get a different linkage (by method)\n",
    "df_consensus_dist_red = 1 - df_consensus_matrix_red\n",
    "link = hc.linkage(scipy.spatial.distance.squareform(df_consensus_dist_red), method='ward')\n",
    "\n",
    "# retrieve clusters using fcluster\n",
    "dist = scipy.spatial.distance.squareform(df_consensus_dist_red)\n",
    "\n",
    "consensus_clst_red = pd.DataFrame(index=X.columns)\n",
    "consensus_clst_red['cluster'] = hc.fcluster(link, thresh * dist.max(), 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f563223-eff2-4df2-93de-6753bafdb7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bar plot showing sizes of each consensus NMF cluster\n",
    "# sns.barplot(\n",
    "#     x=consensus_clst_red.cluster.value_counts().sort_index().index,\n",
    "#     y=consensus_clst_red.cluster.value_counts().sort_index().values\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f83af58-7a5b-498d-8ab3-502856e1b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot showing sizes of each consensus NMF cluster\n",
    "px.bar(\n",
    "    x=consensus_clst_red.cluster.value_counts().sort_index().index,\n",
    "    y=consensus_clst_red.cluster.value_counts().sort_index().values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf230f5-6e4a-4016-a2cc-67e738b5deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color each NMF cluster (default matplotlib colors)\n",
    "\n",
    "#cm = matplotlib.colormaps.get_cmap('tab20')\n",
    "cmb = matplotlib.colormaps.get_cmap('tab20b')\n",
    "cmc = matplotlib.colormaps.get_cmap('tab20c')\n",
    "cm_colors = cmb.colors + cmc.colors\n",
    "\n",
    "consensus_clr_red = dict(zip(sorted(consensus_clst_red.cluster.unique()), cm_colors))\n",
    "consensus_clst_red['color'] = consensus_clst_red.cluster.map(consensus_clr_red)\n",
    "\n",
    "print('Number of colors: ', len(consensus_clr_red))\n",
    "print('Number of clusters', len(consensus_clst_red.cluster.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b54a9-fb22-47f0-879d-9e6e9a3cb121",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 9\n",
    "\n",
    "#legend_TN = [patches.Patch(color=c, label=l) for l,c in mash_color_dict_31.items()] # Mash cluster for legend\n",
    "\n",
    "sns.set(rc={'figure.facecolor':'white'})\n",
    "g = sns.clustermap(\n",
    "    df_consensus_matrix_red,\n",
    "    figsize=(size,size),\n",
    "    row_linkage=link,\n",
    "    #row_colors=phylogroup_clst.color, # Phylogroup colors on left\n",
    "    col_linkage=link,\n",
    "    #col_colors=clst.color, # Mash cluster on top\n",
    "    yticklabels=False,\n",
    "    xticklabels=False,\n",
    "    cmap='hot_r'\n",
    ")\n",
    "\n",
    "#l2=g.ax_heatmap.legend(loc='upper left', bbox_to_anchor=(1.01,0.85), handles=legend_TN,frameon=True)\n",
    "#l2.set_title(title='Mash cluster',prop={'size':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38bbb39-9c99-4539-a282-b6fa4d77ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper diagonal elements of consensus\n",
    "avec = np.array([df_consensus_matrix_red.values[i, j] for i in range(df_consensus_matrix_red.shape[0] - 1)\n",
    "                 for j in range(i + 1, df_consensus_matrix_red.shape[1])])\n",
    "\n",
    "# consensus entries are similarities, conversion to distances\n",
    "Y = 1 - avec\n",
    "Z = hc.linkage(Y, method='ward')\n",
    "\n",
    "# cophenetic correlation coefficient of a hierarchical clustering\n",
    "# defined by the linkage matrix Z and matrix Y from which Z was\n",
    "# generated\n",
    "coph_cor_red, _ = cophenet(Z, Y)\n",
    "\n",
    "coph_cor_red # Cophenetic correlation of reduced consensus matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80603754-f071-48a0-8ee3-ad1936d9e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_red = np.sum(\n",
    "    4 * np.multiply(\n",
    "        df_consensus_matrix_red.values - 0.5,\n",
    "        df_consensus_matrix_red.values - 0.5\n",
    "    )\n",
    ") / consensus_matrix_red.size # same size as df_consensus_matrix_red\n",
    "\n",
    "dispersion_red # Dispersion coefficient of consensus matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017afee7-a513-468c-81ed-ea36090b2005",
   "metadata": {},
   "source": [
    "## Consensus model 3: Infrequent accessory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b43d237-bb3b-4c0d-86c5-88fb2f74ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input matrix\n",
    "X = df_acc_50.copy()\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d025abd-f4c1-4096-b9fa-a354acd9e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of NMF runs (~1 min for 50 runs)\n",
    "n_runs = 3\n",
    "\n",
    "# Rank of NMF (Mash rank for complete strains)\n",
    "rank = RANK\n",
    "\n",
    "# Max iterations per run\n",
    "max_iter = 5_000\n",
    "\n",
    "# Initialize dictionaries to store W and H matrices\n",
    "W_dict_min = {}\n",
    "H_dict_min = {}\n",
    "\n",
    "# Initialize dictionary to store NMF model\n",
    "nmf_min_dict = {}\n",
    "\n",
    "# Store model errors (becomes pandas DataFrame)\n",
    "nmf_min_errors = []\n",
    "\n",
    "# Run NMF num_runs times and store W and H matrices in dictionaries\n",
    "for i in trange(n_runs):\n",
    "    nmf_min = NMF(\n",
    "        n_components=rank,\n",
    "        init='nndsvd', # gives sparser basis matrix\n",
    "        max_iter=max_iter,\n",
    "        random_state=i+15\n",
    "    )\n",
    "    W = nmf_min.fit_transform(X) # basis matrix (gene groupings)\n",
    "    H = nmf_min.components_ # coefficients matrix (strain groupings)\n",
    "    W_dict_min[i] = W\n",
    "    H_dict_min[i] = H\n",
    "    \n",
    "    X_approx = pd.DataFrame(\n",
    "        np.dot(W, H),\n",
    "        index=X.index,\n",
    "        columns=X.columns\n",
    "    )\n",
    "    \n",
    "    nmf_min_dict[i] = nmf_min\n",
    "    \n",
    "    # Store error metrics\n",
    "    entry = {}\n",
    "    entry['run'] = i\n",
    "    entry['rmse']  = np.sqrt(mean_squared_error(X, X_approx))\n",
    "    entry['mae']  = median_absolute_error(X, X_approx)\n",
    "    entry['fro'] = np.linalg.norm(X - X_approx)\n",
    "    entry['ssr'] = np.square(X - X_approx).values.flatten().sum()\n",
    "    \n",
    "    nmf_min_errors.append(entry)\n",
    "\n",
    "nmf_min_errors = pd.DataFrame(nmf_min_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d917f384-5f6b-400e-967d-13403fe88d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the new dictionary\n",
    "conn_dict_min = {}\n",
    "\n",
    "# Loop over each matrix in the H_dict dictionary\n",
    "for key, H in H_dict_min.items():\n",
    "    conn_dict_min[key] = connectivity(X, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1276ff7-26b2-46bb-9904-7c9397252651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consensus matrix for these runs (H matrix, default)\n",
    "consensus_matrix_min = np.zeros(shape=conn_dict_min[0].shape)\n",
    "\n",
    "for key, conn_matrix in conn_dict_min.items():\n",
    "    consensus_matrix_min += conn_matrix\n",
    "\n",
    "consensus_matrix_min /= len(conn_dict)\n",
    "\n",
    "df_consensus_matrix_min = pd.DataFrame(consensus_matrix_min, index=X.columns, columns=X.columns)\n",
    "df_consensus_matrix_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c54330-8313-4589-ae32-093cc3820be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to get different number of clusters\n",
    "\n",
    "# Minimum acceptable value for robust clusters = 50%\n",
    "thresh = 0.5\n",
    "\n",
    "# change this to get a different linkage (by method)\n",
    "df_consensus_dist_min = 1 - df_consensus_matrix_min\n",
    "link = hc.linkage(scipy.spatial.distance.squareform(df_consensus_dist_min), method='ward')\n",
    "\n",
    "# retrieve clusters using fcluster\n",
    "dist = scipy.spatial.distance.squareform(df_consensus_dist_min)\n",
    "\n",
    "consensus_clst_min = pd.DataFrame(index=X.columns)\n",
    "consensus_clst_min['cluster'] = hc.fcluster(link, thresh * dist.max(), 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d57944-644a-490f-b73e-24b90088482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bar plot showing sizes of each consensus NMF cluster\n",
    "# sns.barplot(\n",
    "#     x=consensus_clst_min.cluster.value_counts().sort_index().index,\n",
    "#     y=consensus_clst_min.cluster.value_counts().sort_index().values\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac7aed2-0c33-4bc4-9c61-a65762e92e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot showing sizes of each consensus NMF cluster\n",
    "px.bar(\n",
    "    x=consensus_clst_min.cluster.value_counts().sort_index().index,\n",
    "    y=consensus_clst_min.cluster.value_counts().sort_index().values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b72ed7-434f-447d-81c8-d28f42b018b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color each NMF cluster (default matplotlib colors)\n",
    "\n",
    "#cm = matplotlib.colormaps.get_cmap('tab20')\n",
    "cmb = matplotlib.colormaps.get_cmap('tab20b')\n",
    "cmc = matplotlib.colormaps.get_cmap('tab20c')\n",
    "cm_colors = cmb.colors + cmc.colors\n",
    "\n",
    "consensus_clr_min = dict(zip(sorted(consensus_clst_min.cluster.unique()), cm_colors))\n",
    "consensus_clst_min['color'] = consensus_clst_min.cluster.map(consensus_clr_min)\n",
    "\n",
    "print('Number of colors: ', len(consensus_clr_min))\n",
    "print('Number of clusters', len(consensus_clst_min.cluster.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a86f80-1c43-46e2-b8ef-9dba4fe91afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 9\n",
    "\n",
    "#legend_TN = [patches.Patch(color=c, label=l) for l,c in mash_color_dict_31.items()] # Mash cluster for legend\n",
    "\n",
    "sns.set(rc={'figure.facecolor':'white'})\n",
    "g = sns.clustermap(\n",
    "    df_consensus_matrix_min,\n",
    "    figsize=(size,size),\n",
    "    row_linkage=link,\n",
    "    #row_colors=phylogroup_clst.color, # Phylogroup colors on left\n",
    "    col_linkage=link,\n",
    "    #col_colors=clst.color, # Mash cluster on top\n",
    "    yticklabels=False,\n",
    "    xticklabels=False,\n",
    "    cmap='hot_r'\n",
    ")\n",
    "\n",
    "#l2=g.ax_heatmap.legend(loc='upper left', bbox_to_anchor=(1.01,0.85), handles=legend_TN,frameon=True)\n",
    "#l2.set_title(title='Mash cluster',prop={'size':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5130e9c4-0e9a-4e3d-a8fe-286ff14cd0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper diagonal elements of consensus\n",
    "avec = np.array([df_consensus_matrix_min.values[i, j] for i in range(df_consensus_matrix_min.shape[0] - 1)\n",
    "                 for j in range(i + 1, df_consensus_matrix_min.shape[1])])\n",
    "\n",
    "# consensus entries are similarities, conversion to distances\n",
    "Y = 1 - avec\n",
    "Z = hc.linkage(Y, method='ward')\n",
    "\n",
    "# cophenetic correlation coefficient of a hierarchical clustering\n",
    "# defined by the linkage matrix Z and matrix Y from which Z was\n",
    "# generated\n",
    "coph_cor_min, _ = cophenet(Z, Y)\n",
    "\n",
    "coph_cor_min # Cophenetic correlation of reduced consensus matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38fbaf5-ded1-49d6-9b5b-3527b9c993a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_min = np.sum(\n",
    "    4 * np.multiply(\n",
    "        df_consensus_matrix_min.values - 0.5,\n",
    "        df_consensus_matrix_min.values - 0.5\n",
    "    )\n",
    ") / consensus_matrix_min.size\n",
    "\n",
    "dispersion_min # Dispersion coefficient of consensus matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008db441-711e-4d65-af39-d11668478ad9",
   "metadata": {},
   "source": [
    "## Consensus model 4: Sparse accessory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3302a6-706f-4c2f-a988-14d8800fc46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input matrix\n",
    "X = df_acc_25.copy()\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35459fb6-8e20-4e95-bd88-cc6b90971baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of NMF runs (~1 min for 50 runs)\n",
    "n_runs = 3\n",
    "\n",
    "# Rank of NMF (Mash rank for complete strains)\n",
    "rank = 31\n",
    "\n",
    "# Max iterations per run\n",
    "max_iter = 5_000\n",
    "\n",
    "# Initialize dictionaries to store W and H matrices\n",
    "W_dict_sparse = {}\n",
    "H_dict_sparse = {}\n",
    "\n",
    "# Initialize dictionary to store NMF model\n",
    "nmf_sparse_dict = {}\n",
    "\n",
    "# Store model errors (becomes pandas DataFrame)\n",
    "nmf_sparse_errors = []\n",
    "\n",
    "# Run NMF num_runs times and store W and H matrices in dictionaries\n",
    "for i in trange(n_runs):\n",
    "    nmf_sparse = NMF(\n",
    "        n_components=rank,\n",
    "        init='nndsvd', # gives sparser basis matrix\n",
    "        max_iter=max_iter,\n",
    "        random_state=i+971\n",
    "    )\n",
    "    W = nmf_sparse.fit_transform(X) # basis matrix (gene groupings)\n",
    "    H = nmf_sparse.components_ # coefficients matrix (strain groupings)\n",
    "    W_dict_sparse[i] = W\n",
    "    H_dict_sparse[i] = H\n",
    "    \n",
    "    X_approx = pd.DataFrame(\n",
    "        np.dot(W, H),\n",
    "        index=X.index,\n",
    "        columns=X.columns\n",
    "    )\n",
    "    \n",
    "    nmf_sparse_dict[i] = nmf_min\n",
    "    \n",
    "    # Store error metrics\n",
    "    entry = {}\n",
    "    entry['run'] = i\n",
    "    entry['rmse']  = np.sqrt(mean_squared_error(X, X_approx))\n",
    "    entry['mae']  = median_absolute_error(X, X_approx)\n",
    "    entry['fro'] = np.linalg.norm(X - X_approx)\n",
    "    entry['ssr'] = np.square(X - X_approx).values.flatten().sum()\n",
    "    \n",
    "    nmf_sparse_errors.append(entry)\n",
    "\n",
    "nmf_sparse_errors = pd.DataFrame(nmf_min_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2c4db4-8f95-4232-ae41-401d45f9b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the new dictionary\n",
    "conn_dict_sparse = {}\n",
    "\n",
    "# Loop over each matrix in the H_dict dictionary\n",
    "for key, H in H_dict_sparse.items():\n",
    "    conn_dict_sparse[key] = connectivity(X, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188db6b-d310-4f73-80f1-adfb16886114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consensus matrix for these runs (H matrix, default)\n",
    "consensus_matrix_sparse = np.zeros(shape=conn_dict_sparse[0].shape)\n",
    "\n",
    "for key, conn_matrix in conn_dict_sparse.items():\n",
    "    consensus_matrix_sparse += conn_matrix\n",
    "\n",
    "consensus_matrix_sparse /= len(conn_dict)\n",
    "\n",
    "df_consensus_matrix_sparse = pd.DataFrame(consensus_matrix_sparse, index=X.columns, columns=X.columns)\n",
    "df_consensus_matrix_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5566b61-447c-44a9-8834-3a89cac4edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum acceptable value for robust clusters = 50%\n",
    "thresh = 0.5\n",
    "\n",
    "# change this to get a different linkage (by method)\n",
    "df_consensus_dist_sparse = 1 - df_consensus_matrix_sparse\n",
    "link = hc.linkage(scipy.spatial.distance.squareform(df_consensus_dist_sparse), method='ward')\n",
    "\n",
    "# retrieve clusters using fcluster\n",
    "dist = scipy.spatial.distance.squareform(df_consensus_dist_sparse)\n",
    "\n",
    "consensus_clst_sparse = pd.DataFrame(index=X.columns)\n",
    "consensus_clst_sparse['cluster'] = hc.fcluster(link, thresh * dist.max(), 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1421d8da-5b5d-4c36-9df2-ba9ef77fffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bar plot showing sizes of each consensus NMF cluster\n",
    "# sns.barplot(\n",
    "#     x=consensus_clst_sparse.cluster.value_counts().sort_index().index,\n",
    "#     y=consensus_clst_sparse.cluster.value_counts().sort_index().values\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb52761-dba1-4399-ac67-3c63c9a27e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot showing sizes of each consensus NMF cluster\n",
    "px.bar(\n",
    "    x=consensus_clst_sparse.cluster.value_counts().sort_index().index,\n",
    "    y=consensus_clst_sparse.cluster.value_counts().sort_index().values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1910e14-bea8-46b2-a60d-54adc13e6d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color each NMF cluster (default matplotlib colors)\n",
    "\n",
    "#cm = matplotlib.colormaps.get_cmap('tab20')\n",
    "cmb = matplotlib.colormaps.get_cmap('tab20b')\n",
    "cmc = matplotlib.colormaps.get_cmap('tab20c')\n",
    "cm_colors = cmb.colors + cmc.colors\n",
    "\n",
    "consensus_clr_sparse = dict(zip(sorted(consensus_clst_sparse.cluster.unique()), cm_colors))\n",
    "consensus_clst_sparse['color'] = consensus_clst_sparse.cluster.map(consensus_clr_sparse)\n",
    "\n",
    "print('Number of colors: ', len(consensus_clr_sparse))\n",
    "print('Number of clusters', len(consensus_clst_sparse.cluster.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b93250-8366-4f65-8c92-7b2ed3871560",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 9\n",
    "\n",
    "#legend_TN = [patches.Patch(color=c, label=l) for l,c in mash_color_dict_31.items()] # Mash cluster for legend\n",
    "\n",
    "sns.set(rc={'figure.facecolor':'white'})\n",
    "g = sns.clustermap(\n",
    "    df_consensus_matrix_sparse,\n",
    "    figsize=(size,size),\n",
    "    row_linkage=link,\n",
    "    #row_colors=phylogroup_clst.color, # Phylogroup colors on left\n",
    "    col_linkage=link,\n",
    "    #col_colors=clst.color, # Mash cluster on top\n",
    "    yticklabels=False,\n",
    "    xticklabels=False,\n",
    "    cmap='hot_r'\n",
    ")\n",
    "\n",
    "#l2=g.ax_heatmap.legend(loc='upper left', bbox_to_anchor=(1.01,0.85), handles=legend_TN,frameon=True)\n",
    "#l2.set_title(title='Mash cluster',prop={'size':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb72849-0cfc-4093-aa2c-77cdf72bb99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper diagonal elements of consensus\n",
    "avec = np.array([df_consensus_matrix_sparse.values[i, j] for i in range(df_consensus_matrix_sparse.shape[0] - 1)\n",
    "                 for j in range(i + 1, df_consensus_matrix_sparse.shape[1])])\n",
    "\n",
    "# consensus entries are similarities, conversion to distances\n",
    "Y = 1 - avec\n",
    "Z = hc.linkage(Y, method='ward')\n",
    "\n",
    "# cophenetic correlation coefficient of a hierarchical clustering\n",
    "# defined by the linkage matrix Z and matrix Y from which Z was\n",
    "# generated\n",
    "coph_cor_sparse, _ = cophenet(Z, Y)\n",
    "\n",
    "coph_cor_sparse # Cophenetic correlation of reduced consensus matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e539bee-69db-47ad-ba5b-1ca5a3f99ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_sparse = np.sum(\n",
    "    4 * np.multiply(\n",
    "        df_consensus_matrix_sparse.values - 0.5,\n",
    "        df_consensus_matrix_sparse.values - 0.5\n",
    "    )\n",
    ") / consensus_matrix_sparse.size\n",
    "\n",
    "dispersion_sparse # Dispersion coefficient of consensus matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca7660-412e-4ebf-984b-ebf422e90935",
   "metadata": {},
   "source": [
    "## Meta-consensus model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2539f96-c40f-4794-b3a5-48e5d5b901e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_consensus_matrix.shape == df_consensus_matrix_red.shape == \\\n",
    "    df_consensus_matrix_min.shape == df_consensus_matrix_sparse.shape\n",
    "\n",
    "df_consensus_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7092fc5b-1460-447a-9641-0fc31c7ffef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_consensus_matrix = pd.DataFrame(\n",
    "    np.zeros(df_consensus_matrix.shape),\n",
    "    index=df_consensus_matrix.index,\n",
    "    columns=df_consensus_matrix.columns\n",
    ")\n",
    "\n",
    "df_meta_consensus_matrix = df_consensus_matrix + df_consensus_matrix_red + \\\n",
    "    df_consensus_matrix_min + df_consensus_matrix_sparse\n",
    "\n",
    "df_meta_consensus_matrix /= 4\n",
    "\n",
    "df_meta_consensus_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f1089-8f70-475c-93de-c303ef2f0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum acceptable value for robust clusters = (75%)\n",
    "thresh = 0.75\n",
    "\n",
    "# change this to get a different linkage (by method)\n",
    "df_meta_consensus_dist = 1 - df_meta_consensus_matrix\n",
    "link = hc.linkage(scipy.spatial.distance.squareform(df_meta_consensus_dist), method='ward')\n",
    "\n",
    "# retrieve clusters using fcluster\n",
    "dist = scipy.spatial.distance.squareform(df_meta_consensus_dist)\n",
    "\n",
    "meta_consensus_clst = pd.DataFrame(index=X.columns)\n",
    "meta_consensus_clst['cluster'] = hc.fcluster(link, thresh * dist.max(), 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9596e943-42c5-4ccb-9cc8-78a48aa3407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bar plot showing sizes of each meta-consensus NMF cluster\n",
    "# sns.barplot(\n",
    "#     x=meta_consensus_clst.cluster.value_counts().sort_index().index,\n",
    "#     y=meta_consensus_clst.cluster.value_counts().sort_index().values\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fa582f-3cec-4ece-8d0e-3b3d44ad00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot showing sizes of each meta-consensus NMF cluster\n",
    "px.bar(\n",
    "    x=meta_consensus_clst.cluster.value_counts().sort_index().index,\n",
    "    y=meta_consensus_clst.cluster.value_counts().sort_index().values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff32809-cdb9-46c7-9086-fe2143f2b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color each NMF cluster (default matplotlib colors)\n",
    "\n",
    "cm1 = matplotlib.colormaps.get_cmap('Pastel1')\n",
    "cm2 = matplotlib.colormaps.get_cmap('Pastel2')\n",
    "cmb = matplotlib.colormaps.get_cmap('tab20b')\n",
    "cmc = matplotlib.colormaps.get_cmap('tab20c')\n",
    "cm_colors = cm1.colors + cm2.colors + cmb.colors + cmc.colors\n",
    "\n",
    "meta_consensus_clr = dict(zip(sorted(meta_consensus_clst.cluster.unique()), cm_colors))\n",
    "meta_consensus_clst['color'] = meta_consensus_clst.cluster.map(meta_consensus_clr)\n",
    "\n",
    "print('Number of colors: ', len(meta_consensus_clr))\n",
    "print('Number of clusters', len(meta_consensus_clst.cluster.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e86d16-3aa7-4bb4-b66f-a80c0dd3046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 9\n",
    "\n",
    "#legend_TN = [patches.Patch(color=c, label=l) for l,c in mash_color_dict_31.items()] # Mash cluster for legend\n",
    "\n",
    "sns.set(rc={'figure.facecolor':'white'})\n",
    "g = sns.clustermap(\n",
    "    df_meta_consensus_matrix,\n",
    "    figsize=(size,size),\n",
    "    row_linkage=link,\n",
    "    #row_colors=phylogroup_clst.color, # Phylogroup colors on left\n",
    "    col_linkage=link,\n",
    "    #col_colors=clst.color, # Mash cluster on top\n",
    "    yticklabels=False,\n",
    "    xticklabels=False,\n",
    "    cmap='hot_r'\n",
    ")\n",
    "\n",
    "#l2=g.ax_heatmap.legend(loc='upper left', bbox_to_anchor=(1.01,0.85), handles=legend_TN,frameon=True)\n",
    "#l2.set_title(title='Mash cluster',prop={'size':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4aacc-8915-4fe1-b57a-b23dcb38871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper diagonal elements of consensus\n",
    "avec = np.array([df_meta_consensus_matrix.values[i, j] for i in range(df_meta_consensus_matrix.shape[0] - 1)\n",
    "                 for j in range(i + 1, df_meta_consensus_matrix.shape[1])])\n",
    "\n",
    "# consensus entries are similarities, conversion to distances\n",
    "Y = 1 - avec\n",
    "Z = hc.linkage(Y, method='ward')\n",
    "\n",
    "# cophenetic correlation coefficient of a hierarchical clustering\n",
    "# defined by the linkage matrix Z and matrix Y from which Z was\n",
    "# generated\n",
    "coph_cor_meta, _ = cophenet(Z, Y)\n",
    "\n",
    "coph_cor_meta # Cophenetic correlation of reduced consensus matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea52e42-02bd-4fb9-ad92-05cc8d458764",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_meta = np.sum(\n",
    "    4 * np.multiply(\n",
    "        df_meta_consensus_matrix.values - 0.5,\n",
    "        df_meta_consensus_matrix.values - 0.5\n",
    "    )\n",
    ") / df_meta_consensus_matrix.size\n",
    "\n",
    "dispersion_meta # Dispersion coefficient of consensus matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1af3e10-ed93-4988-941b-5444e24662f8",
   "metadata": {},
   "source": [
    "## Find best run for main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4a736-8e0d-40c8-a7d5-647422e32c48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_nmf_errors.sort_values(by='Frobenius')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b58b610-c2dc-457b-9542-f14657e90738",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = df_nmf_errors['Frobenius'].idxmin()\n",
    "\n",
    "L = W_dict[best_run-1]\n",
    "A = H_dict[best_run-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82df7ea1-6362-4e94-96cd-8369b533a166",
   "metadata": {},
   "source": [
    "## Plotting with species and mash clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47c6aee-ba47-4feb-b625-40727d7ee595",
   "metadata": {},
   "source": [
    "### Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b133e98-8e55-4fc1-bd62-c1843e1a749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_species = metadata.loc[:,[\"genome_id\", \"genome_name\"]]\n",
    "df_species[\"species\"] = df_species[\"genome_name\"].apply(lambda x: x.split()[0]+\" \" +x.split()[1])\n",
    "df_species.set_index('genome_id', inplace=True)\n",
    "\n",
    "df_species.loc[df_species[df_species.species == \"uncultured Enterobacter\"].index, 'species'] = \"Enterobacter sp.\"\n",
    "small_species = df_species.species.value_counts()[(df_species.species.value_counts() < 5)].index\n",
    "df_species.loc[df_species.species.isin(small_species), 'species'] = \"Enterobacter sp.\"\n",
    "\n",
    "cm = matplotlib.colormaps.get_cmap('tab20')\n",
    "clr = dict(zip(sorted(df_species.species.unique()), cm.colors))\n",
    "df_species['color'] = df_species.species.map(clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3dee52-2fce-48ee-a0cd-aa6cc71cc991",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 9\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "#legend_TN = [patches.Patch(color=c, label=l) for l,c in mash_color_dict_31.items()] # Mash cluster for legend\n",
    "\n",
    "legend_TN = [patches.Patch(color=c, label=l) for l,c in clr.items()]\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.facecolor':'white'})\n",
    "g = sns.clustermap(\n",
    "    df_meta_consensus_matrix,\n",
    "    figsize=(size,size),\n",
    "    row_linkage=link,\n",
    "    #row_colors=phylogroup_clst.color, # Phylogroup colors on left\n",
    "    col_linkage=link,\n",
    "    #col_colors=clst.color, # Mash cluster on top\n",
    "    yticklabels=False,\n",
    "    xticklabels=False,\n",
    "    cmap='hot_r',\n",
    "    col_colors=df_species.color\n",
    ")\n",
    "\n",
    "l2=g.ax_heatmap.legend(loc='upper left', bbox_to_anchor=(1.01,0.85), handles=legend_TN,frameon=True)\n",
    "#l2.set_title(title='Mash cluster',prop={'size':10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02fb0c-b520-4556-b2e6-de6123514872",
   "metadata": {},
   "source": [
    "### Mash Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99e853-ea0a-477c-a9c5-4c5e657e4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e78d106-4f95-4347-a932-bf96f67a411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mash = metadata[metadata.genome_status=='Complete'][['genome_id','complete_mash_cluster']].fillna(0)\n",
    "mash = mash.set_index('genome_id')\n",
    "mash.complete_mash_cluster = mash.complete_mash_cluster.apply(float)\n",
    "cm = matplotlib.colormaps.get_cmap('tab20')\n",
    "clr = dict(zip(sorted(mash.complete_mash_cluster.unique()), cm.colors + cm.colors))\n",
    "mash['color'] = mash.complete_mash_cluster.map(clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a40510-7396-4c5c-8386-041cb7e48461",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 9\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "#legend_TN = [patches.Patch(color=c, label=l) for l,c in mash_color_dict_31.items()] # Mash cluster for legend\n",
    "\n",
    "legend_TN = [patches.Patch(color=c, label=l) for l,c in clr.items()]\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.facecolor':'white'})\n",
    "g = sns.clustermap(\n",
    "    df_meta_consensus_matrix,\n",
    "    figsize=(size,size),\n",
    "    row_linkage=link,\n",
    "    #row_colors=phylogroup_clst.color, # Phylogroup colors on left\n",
    "    col_linkage=link,\n",
    "    #col_colors=clst.color, # Mash cluster on top\n",
    "    yticklabels=False,\n",
    "    xticklabels=False,\n",
    "    cmap='hot_r',\n",
    "    col_colors=mash.color\n",
    ")\n",
    "\n",
    "l2=g.ax_heatmap.legend(loc='upper left', bbox_to_anchor=(1.01,0.85), handles=legend_TN,frameon=True)\n",
    "#l2.set_title(title='Mash cluster',prop={'size':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4555040-d9ad-4be8-88c8-f596296834c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e9446-20a5-4628-9833-0086c969bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4c3d4a-4fe8-4bce-94ba-04e4bf047b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "mash_cluster = 16\n",
    "\n",
    "ind = mash[mash.complete_mash_cluster==mash_cluster].index\n",
    "df_species.loc[ind].species.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00a6e25-c086-4511-b384-c8d60ebc75ab",
   "metadata": {},
   "source": [
    "# Save NMF outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff594031-5703-448f-a1c5-9370e2d66bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "L.to_csv('../../data/processed/nmf-outputs/L.csv')\n",
    "A.to_csv('../../data/processed/nmf-outputs/A.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python phylon_analysis",
   "language": "python",
   "name": "phylon_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
